ğŸš€ Overview
This project integrates sentiment analysis with an ESP32 to classify and visualize emotions based on text input. Using machine learning, an SVM model trained on the Sentiment140 dataset processes text to determine sentiment (positive, negative, or neutral). The result is then sent to the ESP32 via MQTT, where it is displayed on an ILI9341 screen along with audio feedback.

ğŸ”— Live Simulation in Wokwi: [Click here to view](https://wokwi.com/projects/423397511758760961)

âœ¨ Features
âœ… Sentiment classification using Support Vector Machine (SVM)
âœ… Real-time MQTT communication between the model and ESP32
âœ… Display sentiment as facial expressions on an ILI9341 screen
âœ… Audio feedback indicating positive or negative sentiment
âœ… Fully simulated in Wokwi, making it hardware-free

ğŸ› ï¸ Tech Stack & Skills Used
ğŸ”¹ Machine Learning: Support Vector Machine (SVM), Sentiment140 dataset
ğŸ”¹ Embedded Systems: ESP32, ILI9341 screen
ğŸ”¹ IoT & Communication: MQTT protocol
ğŸ”¹ Web & API: Flask (for processing sentiment analysis requests)
ğŸ”¹ Simulation: Wokwi (ESP32 online simulator)

ğŸ’¡ How It Works
1ï¸âƒ£ A text input is sent to the Flask-based sentiment analysis model
2ï¸âƒ£ The model classifies it as positive, negative, or neutral
3ï¸âƒ£ The result is transmitted via MQTT to the ESP32
4ï¸âƒ£ The ESP32 displays a happy, sad, or neutral face on the ILI9341 screen
5ï¸âƒ£ An audio message announces whether the sentiment is positive or negative

ğŸ“Œ Future Enhancements
âœ¨ Improve accuracy by experimenting with deep learning models
âœ¨ Add more expressive facial animations
âœ¨ Expand the system for real-time tweet monitoring
